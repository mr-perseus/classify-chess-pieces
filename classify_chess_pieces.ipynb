{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Import Libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30ff4bd7296d39ba"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-09T09:52:22.666203700Z",
     "start_time": "2023-09-09T09:52:19.612481300Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import AlexNet\n",
    "\n",
    "from model_runner import ModelRunner\n",
    "\n",
    "from utils import get_mean_and_std"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test for CUDA\n",
    "Make sure to install the correct CUDA version and packages, see: https://pytorch.org/get-started/locally/"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0810cce0901bf62"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "# check if CUDA is available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-09T09:52:22.694802600Z",
     "start_time": "2023-09-09T09:52:22.649734100Z"
    }
   },
   "id": "c7358d6e495f938a"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-09T09:52:22.832878600Z",
     "start_time": "2023-09-09T09:52:22.751460800Z"
    }
   },
   "id": "2ccc9214777740a0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load Images"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "beef2e82b83e0f6a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Load the dataset and dataloader\n",
    "We do this with a basic transformer which doesn't do anything except converting the images to tensors."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc2b5ccbbf030131"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "images_path = 'data/images'\n",
    "basic_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "untransformed_dataset = datasets.ImageFolder(root=images_path, transform=basic_transforms)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-09T09:52:24.500260500Z",
     "start_time": "2023-09-09T09:52:24.483351100Z"
    }
   },
   "id": "ac7dcfe40c051c1e"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Computing mean and std..\n",
      "Untransformed images, mean is tensor([0.4587, 0.5568, 0.4739]), std is tensor([0.3499, 0.2272, 0.2809])\n"
     ]
    }
   ],
   "source": [
    "mean, std= get_mean_and_std(untransformed_dataset)\n",
    "print(f\"Untransformed images, mean is {mean}, std is {std}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-09T09:52:29.543976Z",
     "start_time": "2023-09-09T09:52:24.688178100Z"
    }
   },
   "id": "c52df3fae11e40cc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Show some images and labels."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "256125cee991731f"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "enhanced_transforms = transforms.Compose([\n",
    "    # transforms.Resize((224, 224)),  # Resize images to 224x224 for AlexNet\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    # transforms.Resize((100, 100)),  # Resize to match the model's input size\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std),\n",
    "])\n",
    "\n",
    "# Dataset with the correctly transformed images\n",
    "dataset = datasets.ImageFolder(root=images_path, transform=enhanced_transforms)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-09T09:53:13.419000100Z",
     "start_time": "2023-09-09T09:53:13.405808100Z"
    }
   },
   "id": "e2be897fa1238bd8"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has classes: ['Black bishop', 'Black king', 'Black knight', 'Black pawn', 'Black queen', 'Black rook', 'White bishop', 'White king', 'White knight', 'White pawn', 'White queen', 'White rook'] (length: 12) Dataset length: is 300\n",
      "==> Computing mean and std..\n",
      "Transformed images, mean is tensor([-0.0534, -0.0052, -0.0156]), std is tensor([0.3581, 0.3869, 0.3755])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset has classes: {dataset.classes} (length: {len(dataset.classes)}) Dataset length: is {len(dataset)}\")\n",
    "\n",
    "mean_updated, std_updated= get_mean_and_std(dataset)\n",
    "print(f\"Transformed images, mean is {mean_updated}, std is {std_updated}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-09T09:53:17.516008400Z",
     "start_time": "2023-09-09T09:53:14.131840300Z"
    }
   },
   "id": "f9e9b96046f0247e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Split Train and Test\n",
    "We split test 0.2, to train 0.8."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46a2363a2f424b4a"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "ratio = 0.8\n",
    "train_size = int(ratio * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-09T09:53:17.517096900Z",
     "start_time": "2023-09-09T09:53:17.513430Z"
    }
   },
   "id": "bda40924cf9e9597"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create the dataloaders\n",
    "We set a feasible batch size (Amount of images is 300).\n",
    "It is important to create the dataloaders after the split!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1de90243757ecf2"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set length: 240, testset length: 60\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train set length: {len(train_dataset)}, testset length: {len(test_dataset)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-09T09:53:17.528244900Z",
     "start_time": "2023-09-09T09:53:17.517096900Z"
    }
   },
   "id": "90e7f01d8eb918dd"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# Train set is 240 images, test set is 60 images. Batch size to 20\n",
    "batch_size = 20\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-09T09:53:18.296386300Z",
     "start_time": "2023-09-09T09:53:18.270502700Z"
    }
   },
   "id": "d3557e340032796a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Do the training with AlexNet"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ae2adeec482c0b5"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Define the network: AlexNet, num_classes is the number of classes in the dataset (from the dataset directly)\u001B[39;00m\n\u001B[0;32m      2\u001B[0m net \u001B[38;5;241m=\u001B[39m AlexNet(num_classes\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(dataset\u001B[38;5;241m.\u001B[39mclasses))\n\u001B[1;32m----> 3\u001B[0m \u001B[43mnet\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# specify loss function\u001B[39;00m\n\u001B[0;32m      6\u001B[0m criterion \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mCrossEntropyLoss()\n",
      "File \u001B[1;32m~\\Documents\\Projects\\classify-chess-pieces\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1145\u001B[0m, in \u001B[0;36mModule.to\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1141\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1142\u001B[0m                     non_blocking, memory_format\u001B[38;5;241m=\u001B[39mconvert_to_format)\n\u001B[0;32m   1143\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, non_blocking)\n\u001B[1;32m-> 1145\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Projects\\classify-chess-pieces\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:797\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    795\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_apply\u001B[39m(\u001B[38;5;28mself\u001B[39m, fn):\n\u001B[0;32m    796\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 797\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    799\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    800\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    801\u001B[0m             \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    802\u001B[0m             \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    807\u001B[0m             \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    808\u001B[0m             \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\Projects\\classify-chess-pieces\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:797\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    795\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_apply\u001B[39m(\u001B[38;5;28mself\u001B[39m, fn):\n\u001B[0;32m    796\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 797\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    799\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    800\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    801\u001B[0m             \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    802\u001B[0m             \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    807\u001B[0m             \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    808\u001B[0m             \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\Projects\\classify-chess-pieces\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:820\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    816\u001B[0m \u001B[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001B[39;00m\n\u001B[0;32m    817\u001B[0m \u001B[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001B[39;00m\n\u001B[0;32m    818\u001B[0m \u001B[38;5;66;03m# `with torch.no_grad():`\u001B[39;00m\n\u001B[0;32m    819\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m--> 820\u001B[0m     param_applied \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    821\u001B[0m should_use_set_data \u001B[38;5;241m=\u001B[39m compute_should_use_set_data(param, param_applied)\n\u001B[0;32m    822\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m should_use_set_data:\n",
      "File \u001B[1;32m~\\Documents\\Projects\\classify-chess-pieces\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1143\u001B[0m, in \u001B[0;36mModule.to.<locals>.convert\u001B[1;34m(t)\u001B[0m\n\u001B[0;32m   1140\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m convert_to_format \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m t\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m5\u001B[39m):\n\u001B[0;32m   1141\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1142\u001B[0m                 non_blocking, memory_format\u001B[38;5;241m=\u001B[39mconvert_to_format)\n\u001B[1;32m-> 1143\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_floating_point\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_complex\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnon_blocking\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# Define the network: AlexNet, num_classes is the number of classes in the dataset (from the dataset directly)\n",
    "net = AlexNet(num_classes=len(dataset.classes))\n",
    "net.to(device)\n",
    "\n",
    "# specify loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer and momentum\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 40\n",
    "\n",
    "runner = ModelRunner(net=net, trainloader=train_dataloader, testloader=test_dataloader, device=device, optimizer=optimizer, criterion=criterion)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    runner.train(epoch)\n",
    "    runner.test(epoch)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-09T09:08:48.023821300Z",
     "start_time": "2023-09-09T09:08:47.085872500Z"
    }
   },
   "id": "9d9d1f243a211f48"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Do the training with ResNet18"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8822e8a484574fc7"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "Train accuracy: 11.25\n",
      "Test accuracy: 11.666666666666666\n",
      "SAVING! Previous best accuracy: 0. New best accuracy: 11.666666666666666\n",
      "\n",
      "Epoch: 1\n",
      "Train accuracy: 6.666666666666667\n",
      "Test accuracy: 10.0\n",
      "\n",
      "Epoch: 2\n",
      "Train accuracy: 8.75\n",
      "Test accuracy: 11.666666666666666\n",
      "\n",
      "Epoch: 3\n",
      "Train accuracy: 12.916666666666666\n",
      "Test accuracy: 6.666666666666667\n",
      "\n",
      "Epoch: 4\n",
      "Train accuracy: 9.166666666666666\n",
      "Test accuracy: 6.666666666666667\n",
      "\n",
      "Epoch: 5\n",
      "Train accuracy: 12.5\n",
      "Test accuracy: 11.666666666666666\n",
      "\n",
      "Epoch: 6\n",
      "Train accuracy: 9.583333333333334\n",
      "Test accuracy: 13.333333333333334\n",
      "SAVING! Previous best accuracy: 11.666666666666666. New best accuracy: 13.333333333333334\n",
      "\n",
      "Epoch: 7\n",
      "Train accuracy: 14.166666666666666\n",
      "Test accuracy: 10.0\n",
      "\n",
      "Epoch: 8\n",
      "Train accuracy: 11.25\n",
      "Test accuracy: 11.666666666666666\n",
      "\n",
      "Epoch: 9\n",
      "Train accuracy: 14.166666666666666\n",
      "Test accuracy: 16.666666666666668\n",
      "SAVING! Previous best accuracy: 13.333333333333334. New best accuracy: 16.666666666666668\n",
      "\n",
      "Epoch: 10\n",
      "Train accuracy: 8.75\n",
      "Test accuracy: 13.333333333333334\n",
      "\n",
      "Epoch: 11\n",
      "Train accuracy: 15.416666666666666\n",
      "Test accuracy: 10.0\n",
      "\n",
      "Epoch: 12\n",
      "Train accuracy: 18.75\n",
      "Test accuracy: 13.333333333333334\n",
      "\n",
      "Epoch: 13\n",
      "Train accuracy: 14.166666666666666\n",
      "Test accuracy: 13.333333333333334\n",
      "\n",
      "Epoch: 14\n",
      "Train accuracy: 16.25\n",
      "Test accuracy: 13.333333333333334\n",
      "\n",
      "Epoch: 15\n",
      "Train accuracy: 15.416666666666666\n",
      "Test accuracy: 13.333333333333334\n",
      "\n",
      "Epoch: 16\n",
      "Train accuracy: 17.083333333333332\n",
      "Test accuracy: 18.333333333333332\n",
      "SAVING! Previous best accuracy: 16.666666666666668. New best accuracy: 18.333333333333332\n",
      "\n",
      "Epoch: 17\n",
      "Train accuracy: 14.583333333333334\n",
      "Test accuracy: 8.333333333333334\n",
      "\n",
      "Epoch: 18\n",
      "Train accuracy: 15.833333333333334\n",
      "Test accuracy: 11.666666666666666\n",
      "\n",
      "Epoch: 19\n",
      "Train accuracy: 15.0\n",
      "Test accuracy: 13.333333333333334\n",
      "\n",
      "Epoch: 20\n",
      "Train accuracy: 17.083333333333332\n",
      "Test accuracy: 20.0\n",
      "SAVING! Previous best accuracy: 18.333333333333332. New best accuracy: 20.0\n",
      "\n",
      "Epoch: 21\n",
      "Train accuracy: 18.75\n",
      "Test accuracy: 10.0\n",
      "\n",
      "Epoch: 22\n",
      "Train accuracy: 17.083333333333332\n",
      "Test accuracy: 13.333333333333334\n",
      "\n",
      "Epoch: 23\n",
      "Train accuracy: 20.0\n",
      "Test accuracy: 13.333333333333334\n",
      "\n",
      "Epoch: 24\n",
      "Train accuracy: 18.75\n",
      "Test accuracy: 21.666666666666668\n",
      "SAVING! Previous best accuracy: 20.0. New best accuracy: 21.666666666666668\n",
      "\n",
      "Epoch: 25\n",
      "Train accuracy: 15.833333333333334\n",
      "Test accuracy: 8.333333333333334\n",
      "\n",
      "Epoch: 26\n",
      "Train accuracy: 18.333333333333332\n",
      "Test accuracy: 15.0\n",
      "\n",
      "Epoch: 27\n",
      "Train accuracy: 17.083333333333332\n",
      "Test accuracy: 6.666666666666667\n",
      "\n",
      "Epoch: 28\n",
      "Train accuracy: 15.0\n",
      "Test accuracy: 15.0\n",
      "\n",
      "Epoch: 29\n",
      "Train accuracy: 16.25\n",
      "Test accuracy: 10.0\n",
      "\n",
      "Epoch: 30\n",
      "Train accuracy: 18.333333333333332\n",
      "Test accuracy: 21.666666666666668\n",
      "\n",
      "Epoch: 31\n",
      "Train accuracy: 17.916666666666668\n",
      "Test accuracy: 23.333333333333332\n",
      "SAVING! Previous best accuracy: 21.666666666666668. New best accuracy: 23.333333333333332\n",
      "\n",
      "Epoch: 32\n",
      "Train accuracy: 21.25\n",
      "Test accuracy: 21.666666666666668\n",
      "\n",
      "Epoch: 33\n",
      "Train accuracy: 21.25\n",
      "Test accuracy: 10.0\n",
      "\n",
      "Epoch: 34\n",
      "Train accuracy: 20.416666666666668\n",
      "Test accuracy: 20.0\n",
      "\n",
      "Epoch: 35\n",
      "Train accuracy: 21.25\n",
      "Test accuracy: 18.333333333333332\n",
      "\n",
      "Epoch: 36\n",
      "Train accuracy: 21.25\n",
      "Test accuracy: 25.0\n",
      "SAVING! Previous best accuracy: 23.333333333333332. New best accuracy: 25.0\n",
      "\n",
      "Epoch: 37\n",
      "Train accuracy: 20.0\n",
      "Test accuracy: 25.0\n",
      "\n",
      "Epoch: 38\n",
      "Train accuracy: 20.416666666666668\n",
      "Test accuracy: 11.666666666666666\n",
      "\n",
      "Epoch: 39\n",
      "Train accuracy: 17.5\n",
      "Test accuracy: 20.0\n",
      "\n",
      "Epoch: 40\n",
      "Train accuracy: 22.5\n",
      "Test accuracy: 13.333333333333334\n",
      "\n",
      "Epoch: 41\n",
      "Train accuracy: 23.75\n",
      "Test accuracy: 20.0\n",
      "\n",
      "Epoch: 42\n",
      "Train accuracy: 19.166666666666668\n",
      "Test accuracy: 20.0\n",
      "\n",
      "Epoch: 43\n",
      "Train accuracy: 21.25\n",
      "Test accuracy: 10.0\n",
      "\n",
      "Epoch: 44\n",
      "Train accuracy: 21.666666666666668\n",
      "Test accuracy: 16.666666666666668\n",
      "\n",
      "Epoch: 45\n",
      "Train accuracy: 19.166666666666668\n",
      "Test accuracy: 11.666666666666666\n",
      "\n",
      "Epoch: 46\n",
      "Train accuracy: 25.833333333333332\n",
      "Test accuracy: 21.666666666666668\n",
      "\n",
      "Epoch: 47\n",
      "Train accuracy: 21.25\n",
      "Test accuracy: 23.333333333333332\n",
      "\n",
      "Epoch: 48\n",
      "Train accuracy: 19.166666666666668\n",
      "Test accuracy: 16.666666666666668\n",
      "\n",
      "Epoch: 49\n",
      "Train accuracy: 16.25\n",
      "Test accuracy: 25.0\n",
      "\n",
      "Epoch: 50\n",
      "Train accuracy: 19.583333333333332\n",
      "Test accuracy: 23.333333333333332\n",
      "\n",
      "Epoch: 51\n",
      "Train accuracy: 18.75\n",
      "Test accuracy: 16.666666666666668\n",
      "\n",
      "Epoch: 52\n",
      "Train accuracy: 17.916666666666668\n",
      "Test accuracy: 21.666666666666668\n",
      "\n",
      "Epoch: 53\n",
      "Train accuracy: 21.666666666666668\n",
      "Test accuracy: 25.0\n",
      "\n",
      "Epoch: 54\n",
      "Train accuracy: 16.666666666666668\n",
      "Test accuracy: 25.0\n",
      "\n",
      "Epoch: 55\n",
      "Train accuracy: 22.5\n",
      "Test accuracy: 10.0\n",
      "\n",
      "Epoch: 56\n",
      "Train accuracy: 22.916666666666668\n",
      "Test accuracy: 25.0\n",
      "\n",
      "Epoch: 57\n",
      "Train accuracy: 21.666666666666668\n",
      "Test accuracy: 16.666666666666668\n",
      "\n",
      "Epoch: 58\n",
      "Train accuracy: 22.083333333333332\n",
      "Test accuracy: 15.0\n",
      "\n",
      "Epoch: 59\n",
      "Train accuracy: 18.75\n",
      "Test accuracy: 25.0\n",
      "\n",
      "Epoch: 60\n",
      "Train accuracy: 24.166666666666668\n",
      "Test accuracy: 16.666666666666668\n",
      "\n",
      "Epoch: 61\n",
      "Train accuracy: 24.583333333333332\n",
      "Test accuracy: 20.0\n",
      "\n",
      "Epoch: 62\n",
      "Train accuracy: 20.416666666666668\n",
      "Test accuracy: 21.666666666666668\n",
      "\n",
      "Epoch: 63\n",
      "Train accuracy: 22.5\n",
      "Test accuracy: 25.0\n",
      "\n",
      "Epoch: 64\n",
      "Train accuracy: 21.25\n",
      "Test accuracy: 16.666666666666668\n",
      "\n",
      "Epoch: 65\n",
      "Train accuracy: 23.75\n",
      "Test accuracy: 11.666666666666666\n",
      "\n",
      "Epoch: 66\n",
      "Train accuracy: 17.083333333333332\n",
      "Test accuracy: 26.666666666666668\n",
      "SAVING! Previous best accuracy: 25.0. New best accuracy: 26.666666666666668\n",
      "\n",
      "Epoch: 67\n",
      "Train accuracy: 19.583333333333332\n",
      "Test accuracy: 28.333333333333332\n",
      "SAVING! Previous best accuracy: 26.666666666666668. New best accuracy: 28.333333333333332\n",
      "\n",
      "Epoch: 68\n",
      "Train accuracy: 23.75\n",
      "Test accuracy: 25.0\n",
      "\n",
      "Epoch: 69\n",
      "Train accuracy: 18.75\n",
      "Test accuracy: 13.333333333333334\n",
      "\n",
      "Epoch: 70\n",
      "Train accuracy: 22.5\n",
      "Test accuracy: 16.666666666666668\n",
      "\n",
      "Epoch: 71\n",
      "Train accuracy: 22.5\n",
      "Test accuracy: 23.333333333333332\n",
      "\n",
      "Epoch: 72\n",
      "Train accuracy: 17.083333333333332\n",
      "Test accuracy: 16.666666666666668\n",
      "\n",
      "Epoch: 73\n",
      "Train accuracy: 23.333333333333332\n",
      "Test accuracy: 11.666666666666666\n",
      "\n",
      "Epoch: 74\n",
      "Train accuracy: 17.916666666666668\n",
      "Test accuracy: 23.333333333333332\n",
      "\n",
      "Epoch: 75\n",
      "Train accuracy: 24.583333333333332\n",
      "Test accuracy: 21.666666666666668\n",
      "\n",
      "Epoch: 76\n",
      "Train accuracy: 22.083333333333332\n",
      "Test accuracy: 38.333333333333336\n",
      "SAVING! Previous best accuracy: 28.333333333333332. New best accuracy: 38.333333333333336\n",
      "\n",
      "Epoch: 77\n",
      "Train accuracy: 22.083333333333332\n",
      "Test accuracy: 18.333333333333332\n",
      "\n",
      "Epoch: 78\n",
      "Train accuracy: 23.333333333333332\n",
      "Test accuracy: 6.666666666666667\n",
      "\n",
      "Epoch: 79\n",
      "Train accuracy: 22.916666666666668\n",
      "Test accuracy: 13.333333333333334\n",
      "\n",
      "Epoch: 80\n",
      "Train accuracy: 20.0\n",
      "Test accuracy: 20.0\n",
      "\n",
      "Epoch: 81\n",
      "Train accuracy: 21.25\n",
      "Test accuracy: 16.666666666666668\n",
      "\n",
      "Epoch: 82\n",
      "Train accuracy: 23.75\n",
      "Test accuracy: 21.666666666666668\n",
      "\n",
      "Epoch: 83\n",
      "Train accuracy: 20.833333333333332\n",
      "Test accuracy: 23.333333333333332\n",
      "\n",
      "Epoch: 84\n",
      "Train accuracy: 21.25\n",
      "Test accuracy: 21.666666666666668\n",
      "\n",
      "Epoch: 85\n",
      "Train accuracy: 24.166666666666668\n",
      "Test accuracy: 16.666666666666668\n",
      "\n",
      "Epoch: 86\n",
      "Train accuracy: 20.416666666666668\n",
      "Test accuracy: 30.0\n",
      "\n",
      "Epoch: 87\n",
      "Train accuracy: 22.916666666666668\n",
      "Test accuracy: 18.333333333333332\n",
      "\n",
      "Epoch: 88\n",
      "Train accuracy: 19.583333333333332\n",
      "Test accuracy: 11.666666666666666\n",
      "\n",
      "Epoch: 89\n",
      "Train accuracy: 21.25\n",
      "Test accuracy: 20.0\n",
      "\n",
      "Epoch: 90\n",
      "Train accuracy: 23.333333333333332\n",
      "Test accuracy: 21.666666666666668\n",
      "\n",
      "Epoch: 91\n",
      "Train accuracy: 22.5\n",
      "Test accuracy: 20.0\n",
      "\n",
      "Epoch: 92\n",
      "Train accuracy: 20.0\n",
      "Test accuracy: 20.0\n",
      "\n",
      "Epoch: 93\n",
      "Train accuracy: 22.916666666666668\n",
      "Test accuracy: 28.333333333333332\n",
      "\n",
      "Epoch: 94\n",
      "Train accuracy: 27.5\n",
      "Test accuracy: 21.666666666666668\n",
      "\n",
      "Epoch: 95\n",
      "Train accuracy: 25.0\n",
      "Test accuracy: 16.666666666666668\n",
      "\n",
      "Epoch: 96\n",
      "Train accuracy: 19.166666666666668\n",
      "Test accuracy: 15.0\n",
      "\n",
      "Epoch: 97\n",
      "Train accuracy: 21.25\n",
      "Test accuracy: 16.666666666666668\n",
      "\n",
      "Epoch: 98\n",
      "Train accuracy: 17.916666666666668\n",
      "Test accuracy: 16.666666666666668\n",
      "\n",
      "Epoch: 99\n",
      "Train accuracy: 26.25\n",
      "Test accuracy: 16.666666666666668\n"
     ]
    }
   ],
   "source": [
    "import resnet\n",
    "\n",
    "# Define the network: ResNet101\n",
    "net = resnet.ResNet18()\n",
    "net.to(device)\n",
    "\n",
    "# specify loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer and momentum\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 100\n",
    "\n",
    "runner = ModelRunner(net=net, trainloader=train_dataloader, testloader=test_dataloader, device=device, optimizer=optimizer, criterion=criterion)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    runner.train(epoch)\n",
    "    runner.test(epoch)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-09T09:55:44.639445300Z",
     "start_time": "2023-09-09T09:53:21.030097300Z"
    }
   },
   "id": "94d8a5a86c1f93c4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b6c26a9ebbc10e99"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
